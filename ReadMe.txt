
Transformer Network for Multi-Tag prediction on Stackoverflow

we aimed to investigate the efficacy of the Transformer Network in tag prediction tasks. The dataset for this study was obtained from the Kaggle website and consisted of Stack Overflow data. The dataset contained 6,034,195 rows and 4 columns: Id, Title, Body, and Tags. The Id column served as a unique identifier for each question, while the Title column contained the questionâ€™s title, the Body column contained the body of the question, and the Tags column contained the associated tags. For this study, only the last three columns were used, and the Id column was removed. Due to the large size of the dataset, only 40,000 rows were selected for analysis. we examined a dataset that includes all tags.
Transformer Network model was trained and evaluated using all tags available in the Stack Overflow dataset. This approach differs from a simple tag prediction model, which typically involves predicting a single or a small number of tags for a given input text. Using all available tags can also lead to increased complexity and computational requirements, as the model must predict a large number of tags for each input text. This can result in longer training times and higher memory usage.